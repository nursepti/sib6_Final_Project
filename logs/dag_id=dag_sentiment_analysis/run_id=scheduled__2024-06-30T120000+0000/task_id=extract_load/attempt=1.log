[2024-06-30T13:32:45.724+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_sentiment_analysis.extract_load scheduled__2024-06-30T12:00:00+00:00 [queued]>
[2024-06-30T13:32:45.755+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_sentiment_analysis.extract_load scheduled__2024-06-30T12:00:00+00:00 [queued]>
[2024-06-30T13:32:45.756+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 2
[2024-06-30T13:32:45.818+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): extract_load> on 2024-06-30 12:00:00+00:00
[2024-06-30T13:32:45.855+0000] {standard_task_runner.py:60} INFO - Started process 491 to run task
[2024-06-30T13:32:45.989+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'dag_sentiment_analysis', 'extract_load', 'scheduled__2024-06-30T12:00:00+00:00', '--job-id', '51', '--raw', '--subdir', 'DAGS_FOLDER/dag_sentiment_analysis.py', '--cfg-path', '/tmp/tmpzep707ey']
[2024-06-30T13:32:46.048+0000] {standard_task_runner.py:88} INFO - Job 51: Subtask extract_load
[2024-06-30T13:32:46.202+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.10/site-packages/***/settings.py:194 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2024-06-30T13:32:46.600+0000] {task_command.py:423} INFO - Running <TaskInstance: dag_sentiment_analysis.extract_load scheduled__2024-06-30T12:00:00+00:00 [running]> on host a9ab29ad88be
[2024-06-30T13:32:47.058+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='de-team' AIRFLOW_CTX_DAG_ID='dag_sentiment_analysis' AIRFLOW_CTX_TASK_ID='extract_load' AIRFLOW_CTX_EXECUTION_DATE='2024-06-30T12:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-30T12:00:00+00:00'
[2024-06-30T13:33:57.364+0000] {logging_mixin.py:188} INFO - SSL handshake failed: ac-mukte2i-shard-00-01.pn34g58.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007) (configured timeouts: socketTimeoutMS: 60000.0ms, connectTimeoutMS: 60000.0ms),SSL handshake failed: ac-mukte2i-shard-00-00.pn34g58.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007) (configured timeouts: socketTimeoutMS: 60000.0ms, connectTimeoutMS: 60000.0ms),SSL handshake failed: ac-mukte2i-shard-00-02.pn34g58.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007) (configured timeouts: socketTimeoutMS: 60000.0ms, connectTimeoutMS: 60000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 66815ea7d351a5a622cb85f1, topology_type: Unknown, servers: [<ServerDescription ('ac-mukte2i-shard-00-00.pn34g58.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-mukte2i-shard-00-00.pn34g58.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007) (configured timeouts: socketTimeoutMS: 60000.0ms, connectTimeoutMS: 60000.0ms)')>, <ServerDescription ('ac-mukte2i-shard-00-01.pn34g58.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-mukte2i-shard-00-01.pn34g58.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007) (configured timeouts: socketTimeoutMS: 60000.0ms, connectTimeoutMS: 60000.0ms)')>, <ServerDescription ('ac-mukte2i-shard-00-02.pn34g58.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-mukte2i-shard-00-02.pn34g58.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007) (configured timeouts: socketTimeoutMS: 60000.0ms, connectTimeoutMS: 60000.0ms)')>]>
[2024-06-30T13:33:57.367+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/plugins/finnhub_mongodb_loader.py", line 7, in extract_load
    collection = mongodb_loader.load('news', 'finnhub_news')
  File "/opt/airflow/plugins/mongodb_loader.py", line 29, in load
    db = mongo_client[database]
TypeError: 'NoneType' object is not subscriptable
[2024-06-30T13:33:57.387+0000] {taskinstance.py:1149} INFO - Marking task as UP_FOR_RETRY. dag_id=dag_sentiment_analysis, task_id=extract_load, execution_date=20240630T120000, start_date=20240630T133245, end_date=20240630T133357
[2024-06-30T13:33:57.416+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 51 for task extract_load ('NoneType' object is not subscriptable; 491)
[2024-06-30T13:33:57.457+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-06-30T13:33:57.505+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-30T13:39:40.603+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_sentiment_analysis.extract_load scheduled__2024-06-30T12:00:00+00:00 [queued]>
[2024-06-30T13:39:40.625+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_sentiment_analysis.extract_load scheduled__2024-06-30T12:00:00+00:00 [queued]>
[2024-06-30T13:39:40.626+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 2
[2024-06-30T13:39:40.667+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): extract_load> on 2024-06-30 12:00:00+00:00
[2024-06-30T13:39:40.686+0000] {standard_task_runner.py:60} INFO - Started process 568 to run task
[2024-06-30T13:39:40.691+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'dag_sentiment_analysis', 'extract_load', 'scheduled__2024-06-30T12:00:00+00:00', '--job-id', '53', '--raw', '--subdir', 'DAGS_FOLDER/dag_sentiment_analysis.py', '--cfg-path', '/tmp/tmph41z79ss']
[2024-06-30T13:39:40.695+0000] {standard_task_runner.py:88} INFO - Job 53: Subtask extract_load
[2024-06-30T13:39:40.756+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.10/site-packages/***/settings.py:194 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2024-06-30T13:39:40.835+0000] {task_command.py:423} INFO - Running <TaskInstance: dag_sentiment_analysis.extract_load scheduled__2024-06-30T12:00:00+00:00 [running]> on host a9ab29ad88be
[2024-06-30T13:39:41.071+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='de-team' AIRFLOW_CTX_DAG_ID='dag_sentiment_analysis' AIRFLOW_CTX_TASK_ID='extract_load' AIRFLOW_CTX_EXECUTION_DATE='2024-06-30T12:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-30T12:00:00+00:00'
[2024-06-30T13:39:56.998+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/urllib3/response.py", line 710, in _error_catcher
    yield
  File "/home/airflow/.local/lib/python3.10/site-packages/urllib3/response.py", line 814, in _raw_read
    data = self._fp_read(amt) if not fp_closed else b""
  File "/home/airflow/.local/lib/python3.10/site-packages/urllib3/response.py", line 799, in _fp_read
    return self._fp.read(amt) if amt is not None else self._fp.read()
  File "/usr/local/lib/python3.10/http/client.py", line 466, in read
    s = self.fp.read(amt)
  File "/usr/local/lib/python3.10/socket.py", line 705, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.10/ssl.py", line 1307, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.10/ssl.py", line 1163, in read
    return self._sslobj.read(len, buffer)
TimeoutError: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/requests/models.py", line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File "/home/airflow/.local/lib/python3.10/site-packages/urllib3/response.py", line 936, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/home/airflow/.local/lib/python3.10/site-packages/urllib3/response.py", line 879, in read
    data = self._raw_read(amt)
  File "/home/airflow/.local/lib/python3.10/site-packages/urllib3/response.py", line 813, in _raw_read
    with self._error_catcher():
  File "/usr/local/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/airflow/.local/lib/python3.10/site-packages/urllib3/response.py", line 715, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.") from e  # type: ignore[arg-type]
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.finnhub.io', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/plugins/finnhub_mongodb_loader.py", line 5, in extract_load
    news = finnhub_loader.scrape_news()
  File "/opt/airflow/plugins/finnhub_loader.py", line 7, in scrape_news
    news = finnhub_client.general_news('general', min_id=0)
  File "/home/airflow/.local/lib/python3.10/site-packages/finnhub/client.py", line 311, in general_news
    return self._get("/news", params={
  File "/home/airflow/.local/lib/python3.10/site-packages/finnhub/client.py", line 71, in _get
    return self._request("get", path, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/finnhub/client.py", line 40, in _request
    response = getattr(self._session, method)(uri, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/requests/sessions.py", line 747, in send
    r.content
  File "/home/airflow/.local/lib/python3.10/site-packages/requests/models.py", line 899, in content
    self._content = b"".join(self.iter_content(CONTENT_CHUNK_SIZE)) or b""
  File "/home/airflow/.local/lib/python3.10/site-packages/requests/models.py", line 822, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.finnhub.io', port=443): Read timed out.
[2024-06-30T13:39:57.086+0000] {taskinstance.py:1149} INFO - Marking task as UP_FOR_RETRY. dag_id=dag_sentiment_analysis, task_id=extract_load, execution_date=20240630T120000, start_date=20240630T133940, end_date=20240630T133957
[2024-06-30T13:39:57.121+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 53 for task extract_load (HTTPSConnectionPool(host='api.finnhub.io', port=443): Read timed out.; 568)
[2024-06-30T13:39:57.173+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-06-30T13:39:57.221+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
